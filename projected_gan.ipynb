{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uncomforming/himatubushi/blob/main/projected_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nagadomi/lbpcascade_animeface.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0xRZA5uIaIP",
        "outputId": "ebedce13-b24b-4610-f57a-f55c5d4ae198"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'lbpcascade_animeface' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ドライブの画像データの前処理\n",
        "①ドライブのマウント\n",
        "\n",
        "② jpg→pngの変換\n",
        "\n",
        "③  正方形に成形\n",
        "\n",
        "④ zip圧縮"
      ],
      "metadata": {
        "id": "0NsAUwmM2U-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "#driveにマウントしてdriveの画像を使えるように\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def crop_max(pil_img, crop_width, crop_height):\n",
        "    img_width, img_height = pil_img.size\n",
        "    return pil_img.crop(((img_width - crop_width) // 2,#left\n",
        "                         (img_height - crop_height) // 2,#upper\n",
        "                         #(0) // 2,#upper\n",
        "                         (img_width + crop_width) // 2,#right\n",
        "                         (img_height + crop_height) // 2))#lower\n",
        "                         #(crop_height)))#lower\n",
        "def crop_max_square(pil_img):\n",
        "    return crop_max(pil_img, max(pil_img.size), max(pil_img.size))\n",
        "def crop_min(pil_img, crop_width, crop_height):\n",
        "    img_width, img_height = pil_img.size\n",
        "    return pil_img.crop(((img_width - crop_width) // 2,#left\n",
        "                         #(img_height - crop_height) // 2,#upper\n",
        "                         (0) // 2,#upper\n",
        "                         (img_width + crop_width) // 2,#right\n",
        "                         #(img_height + crop_height) // 2))#lower\n",
        "                         (crop_height) // 2))#lower\n",
        "def crop_min_square(pil_img):\n",
        "    return crop_min(pil_img, min(pil_img.size), min(pil_img.size))"
      ],
      "metadata": {
        "id": "gkF95Yagpbtt",
        "outputId": "781c95ac-6bc1-4c0f-f97a-3f76847e3fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  i=1\n",
        "  im = Image.open(f'/content/drive/MyDrive/fgosava/0000/{i:03}.jpg')\n",
        "  im=crop_max_square(im)\n",
        "  im.save(f'/content/{i:03}.png')\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "jaDuAR6yIphe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#顔を切り取る（無理）\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def face_cut(img,output_dir):\n",
        "  # 特徴量ファイルをもとに分類器を作成\n",
        "  classifier = cv2.CascadeClassifier('/content/lbpcascade_animeface/lbpcascade_animeface.xml')\n",
        "\n",
        "  # 顔の検出\n",
        "  image = cv2.imread(img)\n",
        "  # グレースケールで処理を高速化\n",
        "  gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "  faces = classifier.detectMultiScale(gray_image)\n",
        "  if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "  for i, (x,y,w,h) in enumerate(faces):\n",
        "      # 一人ずつ顔を切り抜く\n",
        "      face_image = image[y:y+h, x:x+w]\n",
        "      output_path = os.path.join(output_dir,'{0}.jpg'.format(i))\n",
        "      cv2.imwrite(output_path,face_image)"
      ],
      "metadata": {
        "id": "K4u_P0CSI2cf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_cut(\"/content/001.png\",\"/content/faces\")"
      ],
      "metadata": {
        "id": "RZyVpc7vNouk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/fgoface\n",
        "for j in range(342):\n",
        "  i =j+1\n",
        "  try:\n",
        "     #im = Image.open(f'/content/drive/MyDrive/fgosava/0000/{i:03}.jpg')\n",
        "     im=f'/content/drive/MyDrive/fgosava/0000/{i:03}.jpg'\n",
        "     face_cut(im,'/content/faces')\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "sQw_PnDDMirU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "8r1YmuQtO6x4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir fgopng\n",
        "%cd fgopng\n",
        "%mkdir 0000\n",
        "%cd ..\n",
        "%cp /content/drive/MyDrive/fgosava/dataset.json /content/fgopng\n",
        "for j in range(342):\n",
        "  i =j+1\n",
        "  try:\n",
        "     im = Image.open(f'/content/drive/MyDrive/fgosava/0000/{i:03}.jpg')\n",
        "     im=crop_max_square(im)\n",
        "     im.save(f'/content/fgopng/0000/{i:03}.png')\n",
        "  except:\n",
        "    pass\n",
        "shutil.make_archive('/content/zipfgosavasq/', format='zip', root_dir='/content/fgopng')"
      ],
      "metadata": {
        "id": "Nkzl6gp6YjW1",
        "outputId": "6092023c-6c89-4c30-a17e-07c67a49ac89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fgopng\n",
            "/content\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/zipfgosavasq.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shutil.make_archive('/content/zipfgosavasq/', format='zip', root_dir='/content/fgopng')"
      ],
      "metadata": {
        "id": "78WdcpGsM4aV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUaixszCnlKd"
      },
      "source": [
        "\n",
        "# Training Projected GAN\n",
        "This is a self-contained notebook for training Projected GAN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBwzYACTn05w"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. \n",
        "\n",
        "Now, get the repo and install missing dependencies.\n",
        "\n",
        "日本語訳\n",
        "GPU ランタイムを実行していることを確認します。そうでない場合は、メニューの Runtime > Change Runtime Type でハードウェアアクセラレータとして \"GPU\" を選択します。\n",
        "\n",
        "さて、レポを入手し、不足している依存関係をインストールします。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRrYJBn1Yf3q"
      },
      "source": [
        "git pull#コマンド実行\n",
        "\n",
        "git add .#コミット対象に変更\n",
        "\n",
        "git commit#コミット\n",
        "\n",
        "git push#更新を反映\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VZ3pwUJSoOdO"
      },
      "outputs": [],
      "source": [
        "#captureで画面に表示、bashでbashコマンドを有効に（このセル内のみ）\n",
        "%%capture\n",
        "%%bash\n",
        "# clone repo\n",
        "git clone https://github.com/autonomousvision/projected_gan\n",
        "pip install timm dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "i4N21o-gzMjB",
        "outputId": "026765bb-0526-4f41-bca9-74c381098aef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/projected_gan\n"
          ]
        }
      ],
      "source": [
        "%cd projected_gan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0hD7dKQR00t"
      },
      "source": [
        "## Data Preparation\n",
        "データの準備。大きなファイルをdriveから持ってくるからgdownを使う\n",
        "We need to download and prepare the data. In this example, we use the few-shot datasets of the [FastGAN repo](https://github.com/odegeasslbc/FastGAN-pytorch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1mz2_Eynze8K",
        "outputId": "0954ccab-a2bf-4b39-f7e9-23642a9a16e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1aAJCZbXNHyraJ6Mi13dSbe7pTyfPXha0\n",
            "To: /content/projected_gan/few-shot-image-datasets.zip\n",
            "100% 913M/913M [00:03<00:00, 289MB/s]\n"
          ]
        }
      ],
      "source": [
        "#gdownでdriveから大きなファイルをダウンロード\n",
        "!gdown https://drive.google.com/u/0/uc?id=1aAJCZbXNHyraJ6Mi13dSbe7pTyfPXha0&export=download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "S6NTT3zVzesu"
      },
      "outputs": [],
      "source": [
        "#captureで画面に表示\n",
        "%%capture\n",
        "!unzip few-shot-image-datasets.zip\n",
        "!mv few-shot-images data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_TnMmxJrPFZs",
        "outputId": "07adf80f-651b-40d5-c730-eef02627d90f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]\r  0%|          | 4/1000 [00:00<00:29, 33.26it/s]\r  1%|          | 10/1000 [00:00<00:22, 43.97it/s]\r  2%|▏         | 15/1000 [00:00<00:21, 46.28it/s]\r  2%|▏         | 21/1000 [00:00<00:19, 49.48it/s]\r  3%|▎         | 26/1000 [00:00<00:19, 49.28it/s]\r  3%|▎         | 32/1000 [00:00<00:19, 50.45it/s]\r  4%|▍         | 38/1000 [00:00<00:18, 52.36it/s]\r  4%|▍         | 44/1000 [00:00<00:18, 52.91it/s]\r  5%|▌         | 50/1000 [00:00<00:17, 52.80it/s]\r  6%|▌         | 56/1000 [00:01<00:17, 53.01it/s]\r  6%|▌         | 62/1000 [00:01<00:17, 53.92it/s]\r  7%|▋         | 68/1000 [00:01<00:18, 49.38it/s]\r  7%|▋         | 74/1000 [00:01<00:20, 45.40it/s]\r  8%|▊         | 80/1000 [00:01<00:19, 47.70it/s]\r  9%|▊         | 86/1000 [00:01<00:18, 49.38it/s]\r  9%|▉         | 92/1000 [00:01<00:17, 51.17it/s]\r 10%|▉         | 98/1000 [00:01<00:17, 52.55it/s]\r 10%|█         | 104/1000 [00:02<00:16, 53.14it/s]\r 11%|█         | 110/1000 [00:02<00:16, 53.28it/s]\r 12%|█▏        | 116/1000 [00:02<00:16, 54.36it/s]\r 12%|█▏        | 122/1000 [00:02<00:15, 55.00it/s]\r 13%|█▎        | 128/1000 [00:02<00:15, 55.35it/s]\r 13%|█▎        | 134/1000 [00:02<00:15, 54.98it/s]\r 14%|█▍        | 140/1000 [00:02<00:15, 54.89it/s]\r 15%|█▍        | 146/1000 [00:02<00:15, 54.73it/s]\r 15%|█▌        | 152/1000 [00:02<00:15, 55.36it/s]\r 16%|█▌        | 158/1000 [00:03<00:15, 55.72it/s]\r 16%|█▋        | 164/1000 [00:03<00:16, 49.77it/s]\r 17%|█▋        | 170/1000 [00:03<00:16, 51.39it/s]\r 18%|█▊        | 176/1000 [00:03<00:15, 52.70it/s]\r 18%|█▊        | 182/1000 [00:03<00:15, 53.27it/s]\r 19%|█▉        | 188/1000 [00:03<00:15, 53.01it/s]\r 19%|█▉        | 194/1000 [00:03<00:15, 52.80it/s]\r 20%|██        | 200/1000 [00:03<00:14, 53.60it/s]\r 21%|██        | 206/1000 [00:03<00:14, 54.07it/s]\r 21%|██        | 212/1000 [00:04<00:14, 54.92it/s]\r 22%|██▏       | 218/1000 [00:04<00:14, 55.48it/s]\r 22%|██▏       | 224/1000 [00:04<00:13, 55.90it/s]\r 23%|██▎       | 230/1000 [00:04<00:13, 55.67it/s]\r 24%|██▎       | 236/1000 [00:04<00:13, 55.34it/s]\r 24%|██▍       | 242/1000 [00:04<00:13, 54.71it/s]\r 25%|██▍       | 248/1000 [00:04<00:13, 54.61it/s]\r 25%|██▌       | 254/1000 [00:04<00:18, 40.19it/s]\r 26%|██▌       | 259/1000 [00:05<00:19, 38.54it/s]\r 26%|██▋       | 264/1000 [00:05<00:20, 36.50it/s]\r 27%|██▋       | 268/1000 [00:05<00:20, 35.57it/s]\r 27%|██▋       | 272/1000 [00:05<00:21, 33.87it/s]\r 28%|██▊       | 276/1000 [00:05<00:22, 32.02it/s]\r 28%|██▊       | 280/1000 [00:05<00:22, 32.46it/s]\r 28%|██▊       | 284/1000 [00:05<00:21, 33.85it/s]\r 29%|██▉       | 288/1000 [00:06<00:23, 30.57it/s]\r 29%|██▉       | 292/1000 [00:06<00:21, 32.29it/s]\r 30%|██▉       | 296/1000 [00:06<00:21, 32.20it/s]\r 30%|███       | 300/1000 [00:06<00:21, 32.56it/s]\r 30%|███       | 304/1000 [00:06<00:23, 29.74it/s]\r 31%|███       | 308/1000 [00:06<00:23, 29.16it/s]\r 31%|███       | 312/1000 [00:06<00:21, 31.52it/s]\r 32%|███▏      | 316/1000 [00:06<00:20, 32.58it/s]\r 32%|███▏      | 320/1000 [00:07<00:22, 29.84it/s]\r 32%|███▏      | 324/1000 [00:07<00:22, 29.68it/s]\r 33%|███▎      | 330/1000 [00:07<00:18, 35.61it/s]\r 34%|███▎      | 336/1000 [00:07<00:16, 40.83it/s]\r 34%|███▍      | 342/1000 [00:07<00:14, 44.74it/s]\r 35%|███▍      | 348/1000 [00:07<00:13, 47.45it/s]\r 35%|███▌      | 354/1000 [00:07<00:12, 50.02it/s]\r 36%|███▌      | 360/1000 [00:07<00:12, 51.88it/s]\r 37%|███▋      | 366/1000 [00:07<00:11, 52.88it/s]\r 37%|███▋      | 372/1000 [00:08<00:11, 53.11it/s]\r 38%|███▊      | 378/1000 [00:08<00:11, 54.14it/s]\r 38%|███▊      | 384/1000 [00:08<00:11, 53.74it/s]\r 39%|███▉      | 390/1000 [00:08<00:11, 54.46it/s]\r 40%|███▉      | 396/1000 [00:08<00:11, 54.75it/s]\r 40%|████      | 402/1000 [00:08<00:10, 54.99it/s]\r 41%|████      | 408/1000 [00:08<00:10, 53.83it/s]\r 41%|████▏     | 414/1000 [00:08<00:11, 52.70it/s]\r 42%|████▏     | 420/1000 [00:08<00:10, 53.90it/s]\r 43%|████▎     | 426/1000 [00:09<00:10, 54.54it/s]\r 43%|████▎     | 432/1000 [00:09<00:10, 54.41it/s]\r 44%|████▍     | 438/1000 [00:09<00:10, 54.25it/s]\r 44%|████▍     | 444/1000 [00:09<00:10, 54.48it/s]\r 45%|████▌     | 450/1000 [00:09<00:10, 54.64it/s]\r 46%|████▌     | 456/1000 [00:09<00:09, 54.84it/s]\r 46%|████▌     | 462/1000 [00:09<00:10, 53.38it/s]\r 47%|████▋     | 468/1000 [00:09<00:09, 53.61it/s]\r 47%|████▋     | 474/1000 [00:09<00:09, 54.18it/s]\r 48%|████▊     | 480/1000 [00:10<00:09, 54.08it/s]\r 49%|████▊     | 486/1000 [00:10<00:09, 54.79it/s]\r 49%|████▉     | 492/1000 [00:10<00:09, 54.50it/s]\r 50%|████▉     | 498/1000 [00:10<00:09, 55.39it/s]\r 50%|█████     | 504/1000 [00:10<00:08, 55.84it/s]\r 51%|█████     | 510/1000 [00:10<00:08, 56.05it/s]\r 52%|█████▏    | 516/1000 [00:10<00:08, 54.98it/s]\r 52%|█████▏    | 522/1000 [00:10<00:08, 55.16it/s]\r 53%|█████▎    | 528/1000 [00:10<00:08, 55.48it/s]\r 53%|█████▎    | 534/1000 [00:11<00:08, 55.73it/s]\r 54%|█████▍    | 540/1000 [00:11<00:08, 56.06it/s]\r 55%|█████▍    | 546/1000 [00:11<00:08, 55.91it/s]\r 55%|█████▌    | 552/1000 [00:11<00:08, 55.94it/s]\r 56%|█████▌    | 558/1000 [00:11<00:07, 55.41it/s]\r 56%|█████▋    | 564/1000 [00:11<00:07, 55.32it/s]\r 57%|█████▋    | 570/1000 [00:11<00:07, 55.27it/s]\r 58%|█████▊    | 576/1000 [00:11<00:07, 53.79it/s]\r 58%|█████▊    | 582/1000 [00:11<00:07, 52.42it/s]\r 59%|█████▉    | 588/1000 [00:12<00:07, 52.11it/s]\r 59%|█████▉    | 594/1000 [00:12<00:07, 53.09it/s]\r 60%|██████    | 600/1000 [00:12<00:07, 54.60it/s]\r 61%|██████    | 606/1000 [00:12<00:07, 55.39it/s]\r 61%|██████    | 612/1000 [00:12<00:06, 55.73it/s]\r 62%|██████▏   | 618/1000 [00:12<00:06, 55.45it/s]\r 62%|██████▏   | 624/1000 [00:12<00:06, 56.00it/s]\r 63%|██████▎   | 630/1000 [00:12<00:06, 55.67it/s]\r 64%|██████▎   | 636/1000 [00:12<00:06, 55.53it/s]\r 64%|██████▍   | 642/1000 [00:13<00:06, 55.70it/s]\r 65%|██████▍   | 648/1000 [00:13<00:06, 56.13it/s]\r 65%|██████▌   | 654/1000 [00:13<00:06, 56.16it/s]\r 66%|██████▌   | 660/1000 [00:13<00:06, 54.59it/s]\r 67%|██████▋   | 666/1000 [00:13<00:06, 55.13it/s]\r 67%|██████▋   | 672/1000 [00:13<00:05, 55.16it/s]\r 68%|██████▊   | 678/1000 [00:13<00:05, 55.69it/s]\r 68%|██████▊   | 684/1000 [00:13<00:05, 54.08it/s]\r 69%|██████▉   | 690/1000 [00:13<00:05, 54.75it/s]\r 70%|██████▉   | 696/1000 [00:13<00:05, 55.51it/s]\r 70%|███████   | 702/1000 [00:14<00:05, 55.63it/s]\r 71%|███████   | 708/1000 [00:14<00:05, 55.85it/s]\r 71%|███████▏  | 714/1000 [00:14<00:05, 56.26it/s]\r 72%|███████▏  | 720/1000 [00:14<00:04, 56.43it/s]\r 73%|███████▎  | 726/1000 [00:14<00:04, 55.47it/s]\r 73%|███████▎  | 732/1000 [00:14<00:04, 55.01it/s]\r 74%|███████▍  | 738/1000 [00:14<00:04, 54.76it/s]\r 74%|███████▍  | 744/1000 [00:14<00:04, 53.77it/s]\r 75%|███████▌  | 750/1000 [00:14<00:04, 54.23it/s]\r 76%|███████▌  | 756/1000 [00:15<00:04, 54.61it/s]\r 76%|███████▌  | 762/1000 [00:15<00:04, 55.29it/s]\r 77%|███████▋  | 768/1000 [00:15<00:04, 55.41it/s]\r 77%|███████▋  | 774/1000 [00:15<00:04, 55.32it/s]\r 78%|███████▊  | 780/1000 [00:15<00:03, 55.81it/s]\r 79%|███████▊  | 786/1000 [00:15<00:03, 55.80it/s]\r 79%|███████▉  | 792/1000 [00:15<00:03, 55.70it/s]\r 80%|███████▉  | 798/1000 [00:15<00:03, 55.30it/s]\r 80%|████████  | 804/1000 [00:15<00:03, 55.67it/s]\r 81%|████████  | 810/1000 [00:16<00:03, 55.87it/s]\r 82%|████████▏ | 816/1000 [00:16<00:03, 55.82it/s]\r 82%|████████▏ | 822/1000 [00:16<00:03, 55.42it/s]\r 83%|████████▎ | 828/1000 [00:16<00:03, 55.62it/s]\r 83%|████████▎ | 834/1000 [00:16<00:02, 55.67it/s]\r 84%|████████▍ | 840/1000 [00:16<00:02, 54.95it/s]\r 85%|████████▍ | 846/1000 [00:16<00:02, 54.56it/s]\r 85%|████████▌ | 852/1000 [00:16<00:02, 53.66it/s]\r 86%|████████▌ | 858/1000 [00:16<00:02, 54.27it/s]\r 86%|████████▋ | 864/1000 [00:17<00:02, 54.59it/s]\r 87%|████████▋ | 870/1000 [00:17<00:02, 54.81it/s]\r 88%|████████▊ | 876/1000 [00:17<00:02, 55.00it/s]\r 88%|████████▊ | 882/1000 [00:17<00:02, 55.34it/s]\r 89%|████████▉ | 888/1000 [00:17<00:02, 55.83it/s]\r 89%|████████▉ | 894/1000 [00:17<00:01, 55.50it/s]\r 90%|█████████ | 900/1000 [00:17<00:01, 55.81it/s]\r 91%|█████████ | 906/1000 [00:17<00:01, 55.16it/s]\r 91%|█████████ | 912/1000 [00:17<00:01, 54.76it/s]\r 92%|█████████▏| 918/1000 [00:18<00:01, 55.07it/s]\r 92%|█████████▏| 924/1000 [00:18<00:01, 55.42it/s]\r 93%|█████████▎| 930/1000 [00:18<00:01, 55.23it/s]\r 94%|█████████▎| 936/1000 [00:18<00:01, 55.70it/s]\r 94%|█████████▍| 942/1000 [00:18<00:01, 54.61it/s]\r 95%|█████████▍| 948/1000 [00:18<00:01, 50.43it/s]\r 95%|█████████▌| 954/1000 [00:18<00:00, 51.44it/s]\r 96%|█████████▌| 960/1000 [00:18<00:00, 52.02it/s]\r 97%|█████████▋| 966/1000 [00:18<00:00, 52.35it/s]\r 97%|█████████▋| 972/1000 [00:19<00:00, 53.71it/s]\r 98%|█████████▊| 978/1000 [00:19<00:00, 54.17it/s]\r 98%|█████████▊| 984/1000 [00:19<00:00, 54.54it/s]\r 99%|█████████▉| 990/1000 [00:19<00:00, 54.98it/s]\r100%|█████████▉| 996/1000 [00:19<00:00, 55.36it/s]\r100%|██████████| 1000/1000 [00:19<00:00, 51.19it/s]\n"
          ]
        }
      ],
      "source": [
        "#bashでbashコマンドを有効に（このセル内のみ）\n",
        "%%bash\n",
        "python dataset_tool.py --source=./data/art-painting --dest=./data/art_painting256.zip --resolution=256x256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcS63jN9RMdy"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that the data is prepared, we can start training!  The training loop tracks FID, but the computations seems to lead to problems in colab. Hence, it is disable by default (```metrics=[]```). The loop also generates fixed noise samples after a defined amount of ticks, eg. below ```--snap=1```.\n",
        "\n",
        "日本語訳\n",
        "\n",
        "データの準備ができたので、トレーニングを開始します 学習ループはFIDを追跡しますが、その計算がcolabで問題になるようです。そのため、デフォルトでは無効になっています(metrics=[])。また、このループは、定義されたtick数の後に、固定ノイズサンプルを生成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Yrjw0aes9YV_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import dnnlib\n",
        "\n",
        "from training import training_loop\n",
        "from torch_utils import training_stats\n",
        "from train import init_dataset_kwargs\n",
        "from metrics import metric_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Q-VAjxpv9s3T"
      },
      "outputs": [],
      "source": [
        "def launch_training(c, desc, outdir, rank=0):\n",
        "    # Pick output directory.(出力用ディレクトリの選択)\n",
        "    prev_run_dirs = []\n",
        "    if os.path.isdir(outdir):\n",
        "        prev_run_dirs = [x for x in os.listdir(outdir) if os.path.isdir(os.path.join(outdir, x))]\n",
        "\n",
        "    matching_dirs = [re.fullmatch(r'\\d{5}' + f'-{desc}', x) for x in prev_run_dirs if re.fullmatch(r'\\d{5}' + f'-{desc}', x) is not None]\n",
        "    if c.restart_every > 0 and len(matching_dirs) > 0:  # expect unique desc, continue in this directory\n",
        "        assert len(matching_dirs) == 1, f'Multiple directories found for resuming: {matching_dirs}'\n",
        "        c.run_dir = os.path.join(outdir, matching_dirs[0].group())\n",
        "    else:                     # fallback to standard\n",
        "        prev_run_ids = [re.match(r'^\\d+', x) for x in prev_run_dirs]\n",
        "        prev_run_ids = [int(x.group()) for x in prev_run_ids if x is not None]\n",
        "        cur_run_id = max(prev_run_ids, default=-1) + 1\n",
        "        c.run_dir = os.path.join(outdir, f'{cur_run_id:05d}-{desc}')\n",
        "        assert not os.path.exists(c.run_dir)\n",
        "\n",
        "\n",
        "    # Print options.\n",
        "    print()\n",
        "    print('Training options:')\n",
        "    print(json.dumps(c, indent=2))\n",
        "    print()\n",
        "    print(f'Output directory:    {c.run_dir}')\n",
        "    print(f'Number of GPUs:      {c.num_gpus}')\n",
        "    print(f'Batch size:          {c.batch_size} images')\n",
        "    print(f'Training duration:   {c.total_kimg} kimg')\n",
        "    print(f'Dataset path:        {c.training_set_kwargs.path}')\n",
        "    print(f'Dataset size:        {c.training_set_kwargs.max_size} images')\n",
        "    print(f'Dataset resolution:  {c.training_set_kwargs.resolution}')\n",
        "    print(f'Dataset labels:      {c.training_set_kwargs.use_labels}')\n",
        "    print(f'Dataset x-flips:     {c.training_set_kwargs.xflip}')\n",
        "    print()\n",
        "\n",
        "    # Create output directory.(出力用ディレクトリの作成)\n",
        "    print('Creating output directory...')\n",
        "    os.makedirs(c.run_dir, exist_ok=c.restart_every > 0)\n",
        "    with open(os.path.join(c.run_dir, 'training_options.json'), 'wt+') as f:\n",
        "        json.dump(c, f, indent=2)\n",
        "\n",
        "    # Start training\n",
        "    dnnlib.util.Logger(file_name=os.path.join(c.run_dir, 'log.txt'), file_mode='a', should_flush=False)\n",
        "    sync_device = torch.device('cuda', rank) if c.num_gpus > 1 else None\n",
        "    training_stats.init_multiprocessing(rank=rank, sync_device=sync_device)\n",
        "    training_loop.training_loop(rank=rank, **c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yqqzoKQk9tRt"
      },
      "outputs": [],
      "source": [
        "def train(**kwargs):#kwargs=可変引数キーワード引数を辞書として受け取る\n",
        "    # Initialize config.(configの初期化)\n",
        "    opts = dnnlib.EasyDict(kwargs) # Command line arguments.\n",
        "    c = dnnlib.EasyDict() # Main config dict.\n",
        "    c.G_kwargs = dnnlib.EasyDict(class_name=None, z_dim=64, w_dim=128, mapping_kwargs=dnnlib.EasyDict())\n",
        "    c.G_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0,0.99], eps=1e-8)\n",
        "    c.D_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0,0.99], eps=1e-8)\n",
        "    c.data_loader_kwargs = dnnlib.EasyDict(pin_memory=True, prefetch_factor=2)\n",
        "\n",
        "    # Training set.(訓練データの生成)\n",
        "    c.training_set_kwargs, dataset_name = init_dataset_kwargs(data=opts.data)\n",
        "    if opts.cond and not c.training_set_kwargs.use_labels:\n",
        "        raise ValueError('--cond=True requires labels specified in dataset.json')\n",
        "    c.training_set_kwargs.use_labels = opts.cond\n",
        "    c.training_set_kwargs.xflip = opts.mirror\n",
        "\n",
        "    # Hyperparameters & settings.(ハイパーパラメータの設定)\n",
        "    c.num_gpus = opts.gpus\n",
        "    c.batch_size = opts.batch\n",
        "    c.batch_gpu = opts.batch_gpu or opts.batch // opts.gpus\n",
        "    c.G_kwargs.channel_base = opts.cbase\n",
        "    c.G_kwargs.channel_max = opts.cmax\n",
        "    c.G_kwargs.mapping_kwargs.num_layers = 2\n",
        "    c.G_opt_kwargs.lr = (0.002 if opts.cfg == 'stylegan2' else 0.0025) if opts.glr is None else opts.glr\n",
        "    c.D_opt_kwargs.lr = opts.dlr\n",
        "    c.metrics = opts.metrics\n",
        "    c.total_kimg = opts.kimg\n",
        "    c.kimg_per_tick = opts.tick\n",
        "    c.image_snapshot_ticks = c.network_snapshot_ticks = opts.snap\n",
        "    c.random_seed = c.training_set_kwargs.random_seed = opts.seed\n",
        "    c.data_loader_kwargs.num_workers = opts.workers\n",
        "\n",
        "    # Sanity checks.(バグ確認)\n",
        "    if c.batch_size % c.num_gpus != 0:\n",
        "        raise ValueError('--batch must be a multiple of --gpus')\n",
        "    if c.batch_size % (c.num_gpus * c.batch_gpu) != 0:\n",
        "        raise ValueError('--batch must be a multiple of --gpus times --batch-gpu')\n",
        "    if any(not metric_main.is_valid_metric(metric) for metric in c.metrics):\n",
        "        raise ValueError('\\n'.join(['--metrics can only contain the following values:'] + metric_main.list_valid_metrics()))\n",
        "\n",
        "    # Base configuration.(基本構成定義？)(cfgでganの種類を定義(stylegan2 or fastgan))\n",
        "    c.ema_kimg = c.batch_size * 10 / 32\n",
        "    if opts.cfg == 'stylegan2':\n",
        "        c.G_kwargs.class_name = 'pg_modules.networks_stylegan2.Generator'\n",
        "        c.G_kwargs.fused_modconv_default = 'inference_only' # Speed up training by using regular convolutions instead of grouped convolutions.\n",
        "        use_separable_discs = True\n",
        "\n",
        "    elif opts.cfg == 'fastgan':\n",
        "        c.G_kwargs = dnnlib.EasyDict(class_name='pg_modules.networks_fastgan.Generator', cond=opts.cond)\n",
        "        c.G_opt_kwargs.lr = c.D_opt_kwargs.lr = 0.0002\n",
        "        use_separable_discs = False\n",
        "\n",
        "    # Restart.(やり直し)\n",
        "    c.restart_every = opts.restart_every\n",
        "\n",
        "    # Description string.(説明)\n",
        "    desc = f'{opts.cfg:s}-{dataset_name:s}-gpus{c.num_gpus:d}-batch{c.batch_size:d}'\n",
        "    if opts.desc is not None:\n",
        "        desc += f'-{opts.desc}'\n",
        "\n",
        "    # Projected and Multi-Scale Discriminators\n",
        "    c.loss_kwargs = dnnlib.EasyDict(class_name='training.loss.ProjectedGANLoss')\n",
        "    c.D_kwargs = dnnlib.EasyDict(\n",
        "        class_name='pg_modules.discriminator.ProjectedDiscriminator',\n",
        "        diffaug=True,\n",
        "        interp224=(c.training_set_kwargs.resolution < 224),\n",
        "        backbone_kwargs=dnnlib.EasyDict(),\n",
        "    )\n",
        "\n",
        "    c.D_kwargs.backbone_kwargs.cout = 64\n",
        "    c.D_kwargs.backbone_kwargs.expand = True\n",
        "    c.D_kwargs.backbone_kwargs.proj_type = 2\n",
        "    c.D_kwargs.backbone_kwargs.num_discs = 4\n",
        "    c.D_kwargs.backbone_kwargs.separable = use_separable_discs\n",
        "    c.D_kwargs.backbone_kwargs.cond = opts.cond\n",
        "\n",
        "    # Launch.\n",
        "    launch_training(c=c, desc=desc, outdir=opts.outdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uKHfWFKe9tWB",
        "outputId": "6f1755b2-4a76-4cda-9b67-a17d229c4368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"pg_modules.networks_fastgan.Generator\",\n",
            "    \"cond\": false\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0002\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 0\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./data/zipfgosavasq.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 340,\n",
            "    \"xflip\": 1,\n",
            "    \"resolution\": 566,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 64,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 10000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 1,\n",
            "  \"network_snapshot_ticks\": 1,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 20.0,\n",
            "  \"restart_every\": 999999,\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.ProjectedGANLoss\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"pg_modules.discriminator.ProjectedDiscriminator\",\n",
            "    \"diffaug\": true,\n",
            "    \"interp224\": false,\n",
            "    \"backbone_kwargs\": {\n",
            "      \"cout\": 64,\n",
            "      \"expand\": true,\n",
            "      \"proj_type\": 2,\n",
            "      \"num_discs\": 4,\n",
            "      \"separable\": false,\n",
            "      \"cond\": false\n",
            "    }\n",
            "  },\n",
            "  \"run_dir\": \"training-runs/00000-fastgan-zipfgosavasq-gpus1-batch64-\"\n",
            "}\n",
            "\n",
            "Output directory:    training-runs/00000-fastgan-zipfgosavasq-gpus1-batch64-\n",
            "Number of GPUs:      1\n",
            "Batch size:          64 images\n",
            "Training duration:   10000 kimg\n",
            "Dataset path:        ./data/zipfgosavasq.zip\n",
            "Dataset size:        340 images\n",
            "Dataset resolution:  566\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  680\n",
            "Image shape: [3, 566, 566]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b3a60c3b1b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mrestart_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m999999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-22-1817d67a9e4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Launch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mlaunch_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-5e752ff2afa4>\u001b[0m in \u001b[0;36mlaunch_training\u001b[0;34m(c, desc, outdir, rank)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0msync_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gpus\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtraining_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_multiprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtraining_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/projected_gan/training/training_loop.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(run_dir, training_set_kwargs, data_loader_kwargs, G_kwargs, D_kwargs, G_opt_kwargs, D_opt_kwargs, loss_kwargs, metrics, random_seed, num_gpus, rank, batch_size, batch_gpu, ema_kimg, ema_rampup, G_reg_interval, D_reg_interval, total_kimg, kimg_per_tick, image_snapshot_ticks, network_snapshot_ticks, resume_pkl, resume_kimg, cudnn_benchmark, abort_fn, progress_fn, restart_every)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Constructing networks...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mcommon_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_class_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mG_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcommon_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# subclass of torch.nn.Module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_class_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mD_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcommon_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# subclass of torch.nn.Module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mG_ema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/dnnlib/util.py\u001b[0m in \u001b[0;36mconstruct_class_by_name\u001b[0;34m(class_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_class_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;34m\"\"\"Finds the python class with the given name and constructs it with the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_func_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/dnnlib/util.py\u001b[0m in \u001b[0;36mcall_func_by_name\u001b[0;34m(func_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mfunc_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_obj_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/pg_modules/networks_fastgan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, z_dim, c_dim, w_dim, img_resolution, img_channels, ngf, cond, mapping_kwargs, synthesis_kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyMapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# to fit the StyleGAN API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mSynthesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastganSynthesisCond\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mFastganSynthesis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynthesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSynthesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_resolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msynthesis_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/pg_modules/networks_fastgan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ngf, z_dim, nc, img_resolution, lite)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mse_256\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_big\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_resolution\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg_resolution\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 566"
          ]
        }
      ],
      "source": [
        "# start training!\n",
        "%cp /content/zipfgosavasq.zip /content/projected_gan/data\n",
        "train(\n",
        "    outdir='training-runs', #出力用ディレクトリ\n",
        "    cfg='fastgan',#ganの選択\n",
        "    #data='./data/art_painting256.zip', #訓練データ置き場\n",
        "    data='./data/zipfgosavasq.zip', #訓練データ置き場,\n",
        "    gpus=1, #gpusの数設定\n",
        "    batch=64, #batchのsize\n",
        "    cond=False, #\n",
        "    mirror=1, \n",
        "    batch_gpu=8, \n",
        "    cbase=32768, \n",
        "    cmax=512, \n",
        "    glr=None, \n",
        "    dlr=0.002, \n",
        "    desc='', \n",
        "    metrics=[],\n",
        "    kimg=10000, \n",
        "    tick=4, \n",
        "    snap=1, \n",
        "    seed=0, \n",
        "    workers=0,\n",
        "    restart_every=999999,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqYeDzg3KUMG"
      },
      "source": [
        "To inspect the samples, click on the folder symbol on the left and navigate to \n",
        "\n",
        "```projected_gan/training-runs/YOUR_RUN```\n",
        "\n",
        "The files ```fakesXXXXXX.png``` are the samples for a fixed noise vector at point."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ENlESm6i8RnD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "projected_gan.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}