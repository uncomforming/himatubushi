{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uncomforming/himatubushi/blob/main/projected_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ドライブの画像データの前処理\n",
        "①ドライブのマウント\n",
        "\n",
        "② jpg→pngの変換\n",
        "\n",
        "③  正方形に成形\n",
        "\n",
        "④ zip圧縮"
      ],
      "metadata": {
        "id": "0NsAUwmM2U-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_max(pil_img, crop_width, crop_height):\n",
        "    img_width, img_height = pil_img.size\n",
        "    return pil_img.crop(((img_width - crop_width) // 2,#left\n",
        "                         (img_height - crop_height) // 2,#upper\n",
        "                         #(0) // 2,#upper\n",
        "                         (img_width + crop_width) // 2,#right\n",
        "                         (img_height + crop_height) // 2))#lower\n",
        "                         #(crop_height)))#lower\n",
        "def crop_max_square(pil_img):\n",
        "    return crop_max(pil_img, max(pil_img.size), max(pil_img.size))\n",
        "def crop_min(pil_img, crop_width, crop_height):\n",
        "    img_width, img_height = pil_img.size\n",
        "    return pil_img.crop(((img_width - crop_width) // 2,#left\n",
        "                         #(img_height - crop_height) // 2,#upper\n",
        "                         (0) // 2,#upper\n",
        "                         (img_width + crop_width) // 2,#right\n",
        "                         #(img_height + crop_height) // 2))#lower\n",
        "                         (crop_height) // 2))#lower\n",
        "def crop_min_square(pil_img):\n",
        "    return crop_min(pil_img, min(pil_img.size), min(pil_img.size))\n",
        "i=3\n",
        "im = Image.open(f'/content/drive/MyDrive/fgosava/0000/{i:03}.jpg')\n",
        "im=crop_max_square(im)\n",
        "im.save(f'/content/{i:03}.png')"
      ],
      "metadata": {
        "id": "gkF95Yagpbtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import shutil\n",
        "#driveにマウントしてdriveの画像を使えるように\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%mkdir fgopng\n",
        "%cd fgopng\n",
        "%mkdir 0000\n",
        "%cd ..\n",
        "%cp /content/drive/MyDrive/fgosava/dataset.json /content/fgopng\n",
        "for j in range(342):\n",
        "  i =j+1\n",
        "  try:\n",
        "     im = Image.open(f'/content/drive/MyDrive/fgosava/0000/{i:03}.jpg')\n",
        "     im=crop_max_square(im)\n",
        "     im.save(f'/content/fgopng/0000/{i:03}.png')\n",
        "  except:\n",
        "    pass\n",
        "shutil.make_archive('/content/zipfgosavasq/', format='zip', root_dir='/content/testfgo')"
      ],
      "metadata": {
        "id": "Nkzl6gp6YjW1",
        "outputId": "1816f1c6-73de-453d-9a82-e8ab41b9d67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/zipfgosavasq.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUaixszCnlKd"
      },
      "source": [
        "\n",
        "# Training Projected GAN\n",
        "This is a self-contained notebook for training Projected GAN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBwzYACTn05w"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. \n",
        "\n",
        "Now, get the repo and install missing dependencies.\n",
        "\n",
        "日本語訳\n",
        "GPU ランタイムを実行していることを確認します。そうでない場合は、メニューの Runtime > Change Runtime Type でハードウェアアクセラレータとして \"GPU\" を選択します。\n",
        "\n",
        "さて、レポを入手し、不足している依存関係をインストールします。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRrYJBn1Yf3q"
      },
      "source": [
        "git pull#コマンド実行\n",
        "\n",
        "git add .#コミット対象に変更\n",
        "\n",
        "git commit#コミット\n",
        "\n",
        "git push#更新を反映\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "VZ3pwUJSoOdO"
      },
      "outputs": [],
      "source": [
        "#captureで画面に表示、bashでbashコマンドを有効に（このセル内のみ）\n",
        "%%capture\n",
        "%%bash\n",
        "# clone repo\n",
        "git clone https://github.com/autonomousvision/projected_gan\n",
        "pip install timm dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "i4N21o-gzMjB"
      },
      "outputs": [],
      "source": [
        "%cd projected_gan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0hD7dKQR00t"
      },
      "source": [
        "## Data Preparation\n",
        "データの準備。大きなファイルをdriveから持ってくるからgdownを使う\n",
        "We need to download and prepare the data. In this example, we use the few-shot datasets of the [FastGAN repo](https://github.com/odegeasslbc/FastGAN-pytorch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "1mz2_Eynze8K"
      },
      "outputs": [],
      "source": [
        "#gdownでdriveから大きなファイルをダウンロード\n",
        "!gdown https://drive.google.com/u/0/uc?id=1aAJCZbXNHyraJ6Mi13dSbe7pTyfPXha0&export=download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "S6NTT3zVzesu"
      },
      "outputs": [],
      "source": [
        "#captureで画面に表示\n",
        "%%capture\n",
        "!unzip few-shot-image-datasets.zip\n",
        "!mv few-shot-images data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_TnMmxJrPFZs"
      },
      "outputs": [],
      "source": [
        "#bashでbashコマンドを有効に（このセル内のみ）\n",
        "%%bash\n",
        "python dataset_tool.py --source=./data/art-painting --dest=./data/art_painting256.zip --resolution=256x256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcS63jN9RMdy"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that the data is prepared, we can start training!  The training loop tracks FID, but the computations seems to lead to problems in colab. Hence, it is disable by default (```metrics=[]```). The loop also generates fixed noise samples after a defined amount of ticks, eg. below ```--snap=1```.\n",
        "\n",
        "日本語訳\n",
        "\n",
        "データの準備ができたので、トレーニングを開始します 学習ループはFIDを追跡しますが、その計算がcolabで問題になるようです。そのため、デフォルトでは無効になっています(metrics=[])。また、このループは、定義されたtick数の後に、固定ノイズサンプルを生成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Yrjw0aes9YV_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import dnnlib\n",
        "\n",
        "from training import training_loop\n",
        "from torch_utils import training_stats\n",
        "from train import init_dataset_kwargs\n",
        "from metrics import metric_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Q-VAjxpv9s3T"
      },
      "outputs": [],
      "source": [
        "def launch_training(c, desc, outdir, rank=0):\n",
        "    # Pick output directory.(出力用ディレクトリの選択)\n",
        "    prev_run_dirs = []\n",
        "    if os.path.isdir(outdir):\n",
        "        prev_run_dirs = [x for x in os.listdir(outdir) if os.path.isdir(os.path.join(outdir, x))]\n",
        "\n",
        "    matching_dirs = [re.fullmatch(r'\\d{5}' + f'-{desc}', x) for x in prev_run_dirs if re.fullmatch(r'\\d{5}' + f'-{desc}', x) is not None]\n",
        "    if c.restart_every > 0 and len(matching_dirs) > 0:  # expect unique desc, continue in this directory\n",
        "        assert len(matching_dirs) == 1, f'Multiple directories found for resuming: {matching_dirs}'\n",
        "        c.run_dir = os.path.join(outdir, matching_dirs[0].group())\n",
        "    else:                     # fallback to standard\n",
        "        prev_run_ids = [re.match(r'^\\d+', x) for x in prev_run_dirs]\n",
        "        prev_run_ids = [int(x.group()) for x in prev_run_ids if x is not None]\n",
        "        cur_run_id = max(prev_run_ids, default=-1) + 1\n",
        "        c.run_dir = os.path.join(outdir, f'{cur_run_id:05d}-{desc}')\n",
        "        assert not os.path.exists(c.run_dir)\n",
        "\n",
        "\n",
        "    # Print options.\n",
        "    print()\n",
        "    print('Training options:')\n",
        "    print(json.dumps(c, indent=2))\n",
        "    print()\n",
        "    print(f'Output directory:    {c.run_dir}')\n",
        "    print(f'Number of GPUs:      {c.num_gpus}')\n",
        "    print(f'Batch size:          {c.batch_size} images')\n",
        "    print(f'Training duration:   {c.total_kimg} kimg')\n",
        "    print(f'Dataset path:        {c.training_set_kwargs.path}')\n",
        "    print(f'Dataset size:        {c.training_set_kwargs.max_size} images')\n",
        "    print(f'Dataset resolution:  {c.training_set_kwargs.resolution}')\n",
        "    print(f'Dataset labels:      {c.training_set_kwargs.use_labels}')\n",
        "    print(f'Dataset x-flips:     {c.training_set_kwargs.xflip}')\n",
        "    print()\n",
        "\n",
        "    # Create output directory.(出力用ディレクトリの作成)\n",
        "    print('Creating output directory...')\n",
        "    os.makedirs(c.run_dir, exist_ok=c.restart_every > 0)\n",
        "    with open(os.path.join(c.run_dir, 'training_options.json'), 'wt+') as f:\n",
        "        json.dump(c, f, indent=2)\n",
        "\n",
        "    # Start training\n",
        "    dnnlib.util.Logger(file_name=os.path.join(c.run_dir, 'log.txt'), file_mode='a', should_flush=False)\n",
        "    sync_device = torch.device('cuda', rank) if c.num_gpus > 1 else None\n",
        "    training_stats.init_multiprocessing(rank=rank, sync_device=sync_device)\n",
        "    training_loop.training_loop(rank=rank, **c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yqqzoKQk9tRt"
      },
      "outputs": [],
      "source": [
        "def train(**kwargs):#kwargs=可変引数キーワード引数を辞書として受け取る\n",
        "    # Initialize config.(configの初期化)\n",
        "    opts = dnnlib.EasyDict(kwargs) # Command line arguments.\n",
        "    c = dnnlib.EasyDict() # Main config dict.\n",
        "    c.G_kwargs = dnnlib.EasyDict(class_name=None, z_dim=64, w_dim=128, mapping_kwargs=dnnlib.EasyDict())\n",
        "    c.G_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0,0.99], eps=1e-8)\n",
        "    c.D_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0,0.99], eps=1e-8)\n",
        "    c.data_loader_kwargs = dnnlib.EasyDict(pin_memory=True, prefetch_factor=2)\n",
        "\n",
        "    # Training set.(訓練データの生成)\n",
        "    c.training_set_kwargs, dataset_name = init_dataset_kwargs(data=opts.data)\n",
        "    if opts.cond and not c.training_set_kwargs.use_labels:\n",
        "        raise ValueError('--cond=True requires labels specified in dataset.json')\n",
        "    c.training_set_kwargs.use_labels = opts.cond\n",
        "    c.training_set_kwargs.xflip = opts.mirror\n",
        "\n",
        "    # Hyperparameters & settings.(ハイパーパラメータの設定)\n",
        "    c.num_gpus = opts.gpus\n",
        "    c.batch_size = opts.batch\n",
        "    c.batch_gpu = opts.batch_gpu or opts.batch // opts.gpus\n",
        "    c.G_kwargs.channel_base = opts.cbase\n",
        "    c.G_kwargs.channel_max = opts.cmax\n",
        "    c.G_kwargs.mapping_kwargs.num_layers = 2\n",
        "    c.G_opt_kwargs.lr = (0.002 if opts.cfg == 'stylegan2' else 0.0025) if opts.glr is None else opts.glr\n",
        "    c.D_opt_kwargs.lr = opts.dlr\n",
        "    c.metrics = opts.metrics\n",
        "    c.total_kimg = opts.kimg\n",
        "    c.kimg_per_tick = opts.tick\n",
        "    c.image_snapshot_ticks = c.network_snapshot_ticks = opts.snap\n",
        "    c.random_seed = c.training_set_kwargs.random_seed = opts.seed\n",
        "    c.data_loader_kwargs.num_workers = opts.workers\n",
        "\n",
        "    # Sanity checks.(バグ確認)\n",
        "    if c.batch_size % c.num_gpus != 0:\n",
        "        raise ValueError('--batch must be a multiple of --gpus')\n",
        "    if c.batch_size % (c.num_gpus * c.batch_gpu) != 0:\n",
        "        raise ValueError('--batch must be a multiple of --gpus times --batch-gpu')\n",
        "    if any(not metric_main.is_valid_metric(metric) for metric in c.metrics):\n",
        "        raise ValueError('\\n'.join(['--metrics can only contain the following values:'] + metric_main.list_valid_metrics()))\n",
        "\n",
        "    # Base configuration.(基本構成定義？)(cfgでganの種類を定義(stylegan2 or fastgan))\n",
        "    c.ema_kimg = c.batch_size * 10 / 32\n",
        "    if opts.cfg == 'stylegan2':\n",
        "        c.G_kwargs.class_name = 'pg_modules.networks_stylegan2.Generator'\n",
        "        c.G_kwargs.fused_modconv_default = 'inference_only' # Speed up training by using regular convolutions instead of grouped convolutions.\n",
        "        use_separable_discs = True\n",
        "\n",
        "    elif opts.cfg == 'fastgan':\n",
        "        c.G_kwargs = dnnlib.EasyDict(class_name='pg_modules.networks_fastgan.Generator', cond=opts.cond)\n",
        "        c.G_opt_kwargs.lr = c.D_opt_kwargs.lr = 0.0002\n",
        "        use_separable_discs = False\n",
        "\n",
        "    # Restart.(やり直し)\n",
        "    c.restart_every = opts.restart_every\n",
        "\n",
        "    # Description string.(説明)\n",
        "    desc = f'{opts.cfg:s}-{dataset_name:s}-gpus{c.num_gpus:d}-batch{c.batch_size:d}'\n",
        "    if opts.desc is not None:\n",
        "        desc += f'-{opts.desc}'\n",
        "\n",
        "    # Projected and Multi-Scale Discriminators\n",
        "    c.loss_kwargs = dnnlib.EasyDict(class_name='training.loss.ProjectedGANLoss')\n",
        "    c.D_kwargs = dnnlib.EasyDict(\n",
        "        class_name='pg_modules.discriminator.ProjectedDiscriminator',\n",
        "        diffaug=True,\n",
        "        interp224=(c.training_set_kwargs.resolution < 224),\n",
        "        backbone_kwargs=dnnlib.EasyDict(),\n",
        "    )\n",
        "\n",
        "    c.D_kwargs.backbone_kwargs.cout = 64\n",
        "    c.D_kwargs.backbone_kwargs.expand = True\n",
        "    c.D_kwargs.backbone_kwargs.proj_type = 2\n",
        "    c.D_kwargs.backbone_kwargs.num_discs = 4\n",
        "    c.D_kwargs.backbone_kwargs.separable = use_separable_discs\n",
        "    c.D_kwargs.backbone_kwargs.cond = opts.cond\n",
        "\n",
        "    # Launch.\n",
        "    launch_training(c=c, desc=desc, outdir=opts.outdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uKHfWFKe9tWB",
        "outputId": "253b3bbb-b36c-4455-eba4-93c35d47b2cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ClickException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/projected_gan/train.py\u001b[0m in \u001b[0;36minit_dataset_kwargs\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdataset_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEasyDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training.dataset.ImageFolderDataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxflip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mdataset_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_class_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Subclass of training.dataset.Dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m \u001b[0;31m# Be explicit about resolution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/dnnlib/util.py\u001b[0m in \u001b[0;36mconstruct_class_by_name\u001b[0;34m(class_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;34m\"\"\"Finds the python class with the given name and constructs it with the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_func_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/dnnlib/util.py\u001b[0m in \u001b[0;36mcall_func_by_name\u001b[0;34m(func_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/training/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, resolution, **super_kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_fnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/training/dataset.py\u001b[0m in \u001b[0;36m_get_zipfile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zipfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zipfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/zipfgosavasq.zip'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mClickException\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-3fccae7a9de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mrestart_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m999999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-46-1817d67a9e4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Training set.(訓練データの生成)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_set_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dataset_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_set_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--cond=True requires labels specified in dataset.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/train.py\u001b[0m in \u001b[0;36minit_dataset_kwargs\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClickException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'--data: {err}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClickException\u001b[0m: --data: [Errno 2] No such file or directory: './data/zipfgosavasq.zip'"
          ]
        }
      ],
      "source": [
        "# start training!\n",
        "%cp /content/zipfgosavasq.zip /content/projected_gan/data\n",
        "train(\n",
        "    outdir='training-runs', #出力用ディレクトリ\n",
        "    cfg='fastgan',#ganの選択\n",
        "    #data='./data/art_painting256.zip', #訓練データ置き場\n",
        "    data='./data/zipfgosavasq.zip', #訓練データ置き場,\n",
        "    gpus=1, #gpusの数設定\n",
        "    batch=64, #batchのsize\n",
        "    cond=False, #\n",
        "    mirror=1, \n",
        "    batch_gpu=8, \n",
        "    cbase=32768, \n",
        "    cmax=512, \n",
        "    glr=None, \n",
        "    dlr=0.002, \n",
        "    desc='', \n",
        "    metrics=[],\n",
        "    kimg=10000, \n",
        "    tick=4, \n",
        "    snap=1, \n",
        "    seed=0, \n",
        "    workers=0,\n",
        "    restart_every=999999,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqYeDzg3KUMG"
      },
      "source": [
        "To inspect the samples, click on the folder symbol on the left and navigate to \n",
        "\n",
        "```projected_gan/training-runs/YOUR_RUN```\n",
        "\n",
        "The files ```fakesXXXXXX.png``` are the samples for a fixed noise vector at point."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ENlESm6i8RnD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "projected_gan.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}