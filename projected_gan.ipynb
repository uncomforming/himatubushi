{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uncomforming/himatubushi/blob/main/projected_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ドライブの画像データの前処理\n",
        "①ドライブのマウント\n",
        "\n",
        "② jpg→pngの変換\n",
        "\n",
        "③  正方形に成形\n",
        "\n",
        "④ zip圧縮"
      ],
      "metadata": {
        "id": "0NsAUwmM2U-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_max(pil_img, crop_width, crop_height):\n",
        "    img_width, img_height = pil_img.size\n",
        "    return pil_img.crop(((img_width - crop_width) // 2,#left\n",
        "                         (img_height - crop_height) // 2,#upper\n",
        "                         #(0) // 2,#upper\n",
        "                         (img_width + crop_width) // 2,#right\n",
        "                         (img_height + crop_height) // 2))#lower\n",
        "                         #(crop_height)))#lower\n",
        "def crop_max_square(pil_img):\n",
        "    return crop_max(pil_img, max(pil_img.size), max(pil_img.size))\n",
        "def crop_min(pil_img, crop_width, crop_height):\n",
        "    img_width, img_height = pil_img.size\n",
        "    return pil_img.crop(((img_width - crop_width) // 2,#left\n",
        "                         #(img_height - crop_height) // 2,#upper\n",
        "                         (0) // 2,#upper\n",
        "                         (img_width + crop_width) // 2,#right\n",
        "                         #(img_height + crop_height) // 2))#lower\n",
        "                         (crop_height) // 2))#lower\n",
        "def crop_min_square(pil_img):\n",
        "    return crop_min(pil_img, min(pil_img.size), min(pil_img.size))\n",
        "i=3\n",
        "im = Image.open(f'/content/drive/MyDrive/fgosava/0000/{i:03}.jpg')\n",
        "im=crop_max_square(im)\n",
        "im.save(f'/content/{i:03}.png')"
      ],
      "metadata": {
        "id": "gkF95Yagpbtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import shutil\n",
        "#driveにマウントしてdriveの画像を使えるように\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%mkdir fgopng\n",
        "%cd fgopng\n",
        "%mkdir 0000\n",
        "%cd ..\n",
        "%cp /content/drive/MyDrive/fgosava/dataset.json /content/fgopng\n",
        "for j in range(342):\n",
        "  i =j+1\n",
        "  try:\n",
        "     im = Image.open(f'/content/drive/MyDrive/fgosava/0000/{i:03}.jpg')\n",
        "     im=crop_max_square(im)\n",
        "     im.save(f'/content/fgopngsqm/0000/{i:03}.png')\n",
        "  except:\n",
        "    pass\n",
        "shutil.make_archive('/content/zipfgosavasq/', format='zip', root_dir='/content/fgopngsqm')"
      ],
      "metadata": {
        "id": "Nkzl6gp6YjW1",
        "outputId": "dfcfa612-ee5a-4ac3-cd76-b2ea76327e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/zipfgosavasq.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUaixszCnlKd"
      },
      "source": [
        "\n",
        "# Training Projected GAN\n",
        "This is a self-contained notebook for training Projected GAN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBwzYACTn05w"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. \n",
        "\n",
        "Now, get the repo and install missing dependencies.\n",
        "\n",
        "日本語訳\n",
        "GPU ランタイムを実行していることを確認します。そうでない場合は、メニューの Runtime > Change Runtime Type でハードウェアアクセラレータとして \"GPU\" を選択します。\n",
        "\n",
        "さて、レポを入手し、不足している依存関係をインストールします。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRrYJBn1Yf3q"
      },
      "source": [
        "git pull#コマンド実行\n",
        "\n",
        "git add .#コミット対象に変更\n",
        "\n",
        "git commit#コミット\n",
        "\n",
        "git push#更新を反映\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ3pwUJSoOdO"
      },
      "outputs": [],
      "source": [
        "#captureで画面に表示、bashでbashコマンドを有効に（このセル内のみ）\n",
        "%%capture\n",
        "%%bash\n",
        "# clone repo\n",
        "git clone https://github.com/autonomousvision/projected_gan\n",
        "pip install timm dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4N21o-gzMjB",
        "outputId": "280c52b0-fd57-4d4e-e716-3eb061dc6df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/projected_gan\n"
          ]
        }
      ],
      "source": [
        "%cd projected_gan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0hD7dKQR00t"
      },
      "source": [
        "## Data Preparation\n",
        "データの準備。大きなファイルをdriveから持ってくるからgdownを使う\n",
        "We need to download and prepare the data. In this example, we use the few-shot datasets of the [FastGAN repo](https://github.com/odegeasslbc/FastGAN-pytorch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mz2_Eynze8K",
        "outputId": "8e8b5540-95c8-43a6-e91f-fc2d4ff23670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1aAJCZbXNHyraJ6Mi13dSbe7pTyfPXha0\n",
            "To: /content/projected_gan/few-shot-image-datasets.zip\n",
            "100% 913M/913M [00:06<00:00, 139MB/s]\n"
          ]
        }
      ],
      "source": [
        "#gdownでdriveから大きなファイルをダウンロード\n",
        "!gdown https://drive.google.com/u/0/uc?id=1aAJCZbXNHyraJ6Mi13dSbe7pTyfPXha0&export=download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6NTT3zVzesu"
      },
      "outputs": [],
      "source": [
        "#captureで画面に表示\n",
        "%%capture\n",
        "!unzip few-shot-image-datasets.zip\n",
        "!mv few-shot-images data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TnMmxJrPFZs",
        "outputId": "b240b7df-1c06-4cde-a28b-983bc962dff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]\r  1%|          | 6/1000 [00:00<00:18, 53.82it/s]\r  1%|          | 12/1000 [00:00<00:17, 55.49it/s]\r  2%|▏         | 18/1000 [00:00<00:17, 54.93it/s]\r  2%|▏         | 24/1000 [00:00<00:17, 55.42it/s]\r  3%|▎         | 30/1000 [00:00<00:17, 54.58it/s]\r  4%|▎         | 36/1000 [00:00<00:17, 55.19it/s]\r  4%|▍         | 42/1000 [00:00<00:17, 55.40it/s]\r  5%|▍         | 48/1000 [00:00<00:17, 55.73it/s]\r  5%|▌         | 54/1000 [00:00<00:17, 55.22it/s]\r  6%|▌         | 60/1000 [00:01<00:17, 54.41it/s]\r  7%|▋         | 66/1000 [00:01<00:16, 55.19it/s]\r  7%|▋         | 72/1000 [00:01<00:16, 55.65it/s]\r  8%|▊         | 78/1000 [00:01<00:16, 56.77it/s]\r  8%|▊         | 84/1000 [00:01<00:16, 56.83it/s]\r  9%|▉         | 90/1000 [00:01<00:16, 56.18it/s]\r 10%|▉         | 96/1000 [00:01<00:16, 56.36it/s]\r 10%|█         | 102/1000 [00:01<00:16, 56.02it/s]\r 11%|█         | 108/1000 [00:01<00:15, 56.25it/s]\r 11%|█▏        | 114/1000 [00:02<00:15, 56.36it/s]\r 12%|█▏        | 120/1000 [00:02<00:15, 56.80it/s]\r 13%|█▎        | 126/1000 [00:02<00:15, 57.45it/s]\r 13%|█▎        | 132/1000 [00:02<00:15, 57.48it/s]\r 14%|█▍        | 138/1000 [00:02<00:14, 57.52it/s]\r 14%|█▍        | 144/1000 [00:02<00:14, 57.77it/s]\r 15%|█▌        | 150/1000 [00:02<00:14, 56.93it/s]\r 16%|█▌        | 156/1000 [00:02<00:14, 56.86it/s]\r 16%|█▌        | 162/1000 [00:02<00:14, 56.78it/s]\r 17%|█▋        | 168/1000 [00:03<00:16, 51.19it/s]\r 17%|█▋        | 174/1000 [00:03<00:15, 53.15it/s]\r 18%|█▊        | 180/1000 [00:03<00:15, 54.25it/s]\r 19%|█▊        | 186/1000 [00:03<00:14, 54.69it/s]\r 19%|█▉        | 192/1000 [00:03<00:14, 55.30it/s]\r 20%|█▉        | 198/1000 [00:03<00:14, 56.04it/s]\r 20%|██        | 204/1000 [00:03<00:14, 55.80it/s]\r 21%|██        | 210/1000 [00:03<00:14, 56.31it/s]\r 22%|██▏       | 216/1000 [00:03<00:13, 56.83it/s]\r 22%|██▏       | 222/1000 [00:03<00:13, 57.22it/s]\r 23%|██▎       | 228/1000 [00:04<00:13, 57.48it/s]\r 23%|██▎       | 234/1000 [00:04<00:13, 56.82it/s]\r 24%|██▍       | 240/1000 [00:04<00:13, 57.01it/s]\r 25%|██▍       | 246/1000 [00:04<00:13, 57.05it/s]\r 25%|██▌       | 252/1000 [00:04<00:13, 56.34it/s]\r 26%|██▌       | 258/1000 [00:04<00:13, 55.30it/s]\r 26%|██▋       | 264/1000 [00:04<00:13, 55.86it/s]\r 27%|██▋       | 270/1000 [00:04<00:13, 55.80it/s]\r 28%|██▊       | 276/1000 [00:04<00:12, 56.11it/s]\r 28%|██▊       | 282/1000 [00:05<00:12, 56.50it/s]\r 29%|██▉       | 288/1000 [00:05<00:12, 56.83it/s]\r 29%|██▉       | 294/1000 [00:05<00:12, 57.28it/s]\r 30%|███       | 300/1000 [00:05<00:12, 57.04it/s]\r 31%|███       | 306/1000 [00:05<00:12, 57.68it/s]\r 31%|███       | 312/1000 [00:05<00:11, 58.10it/s]\r 32%|███▏      | 318/1000 [00:05<00:11, 57.17it/s]\r 32%|███▏      | 324/1000 [00:05<00:11, 57.53it/s]\r 33%|███▎      | 330/1000 [00:05<00:11, 57.48it/s]\r 34%|███▎      | 336/1000 [00:05<00:11, 56.98it/s]\r 34%|███▍      | 342/1000 [00:06<00:11, 57.04it/s]\r 35%|███▍      | 348/1000 [00:06<00:11, 57.26it/s]\r 35%|███▌      | 354/1000 [00:06<00:11, 57.34it/s]\r 36%|███▌      | 360/1000 [00:06<00:11, 56.74it/s]\r 37%|███▋      | 366/1000 [00:06<00:11, 56.95it/s]\r 37%|███▋      | 372/1000 [00:06<00:10, 57.32it/s]\r 38%|███▊      | 378/1000 [00:06<00:10, 57.13it/s]\r 38%|███▊      | 384/1000 [00:06<00:10, 57.61it/s]\r 39%|███▉      | 390/1000 [00:06<00:10, 57.60it/s]\r 40%|███▉      | 396/1000 [00:07<00:10, 56.78it/s]\r 40%|████      | 402/1000 [00:07<00:10, 56.95it/s]\r 41%|████      | 408/1000 [00:07<00:10, 57.13it/s]\r 41%|████▏     | 414/1000 [00:07<00:10, 57.22it/s]\r 42%|████▏     | 420/1000 [00:07<00:10, 57.66it/s]\r 43%|████▎     | 426/1000 [00:07<00:09, 57.63it/s]\r 43%|████▎     | 432/1000 [00:07<00:09, 57.09it/s]\r 44%|████▍     | 438/1000 [00:07<00:10, 55.25it/s]\r 44%|████▍     | 444/1000 [00:07<00:10, 51.86it/s]\r 45%|████▌     | 450/1000 [00:08<00:10, 53.19it/s]\r 46%|████▌     | 456/1000 [00:08<00:10, 54.27it/s]\r 46%|████▌     | 462/1000 [00:08<00:09, 55.41it/s]\r 47%|████▋     | 468/1000 [00:08<00:09, 56.04it/s]\r 47%|████▋     | 474/1000 [00:08<00:09, 56.43it/s]\r 48%|████▊     | 480/1000 [00:08<00:09, 56.99it/s]\r 49%|████▊     | 486/1000 [00:08<00:09, 56.82it/s]\r 49%|████▉     | 492/1000 [00:08<00:09, 56.43it/s]\r 50%|████▉     | 499/1000 [00:08<00:08, 57.51it/s]\r 50%|█████     | 505/1000 [00:08<00:08, 57.62it/s]\r 51%|█████     | 511/1000 [00:09<00:08, 57.76it/s]\r 52%|█████▏    | 517/1000 [00:09<00:08, 58.00it/s]\r 52%|█████▏    | 523/1000 [00:09<00:08, 57.98it/s]\r 53%|█████▎    | 529/1000 [00:09<00:08, 57.80it/s]\r 54%|█████▎    | 535/1000 [00:09<00:08, 57.88it/s]\r 54%|█████▍    | 541/1000 [00:09<00:08, 56.29it/s]\r 55%|█████▍    | 547/1000 [00:09<00:08, 55.91it/s]\r 55%|█████▌    | 553/1000 [00:09<00:07, 56.58it/s]\r 56%|█████▌    | 559/1000 [00:09<00:07, 56.91it/s]\r 56%|█████▋    | 565/1000 [00:10<00:07, 57.05it/s]\r 57%|█████▋    | 571/1000 [00:10<00:07, 57.41it/s]\r 58%|█████▊    | 577/1000 [00:10<00:07, 57.82it/s]\r 58%|█████▊    | 583/1000 [00:10<00:07, 57.36it/s]\r 59%|█████▉    | 589/1000 [00:10<00:07, 57.90it/s]\r 60%|█████▉    | 596/1000 [00:10<00:06, 58.46it/s]\r 60%|██████    | 602/1000 [00:10<00:06, 58.57it/s]\r 61%|██████    | 608/1000 [00:10<00:06, 58.05it/s]\r 61%|██████▏   | 614/1000 [00:10<00:06, 57.93it/s]\r 62%|██████▏   | 620/1000 [00:10<00:06, 56.47it/s]\r 63%|██████▎   | 626/1000 [00:11<00:06, 55.58it/s]\r 63%|██████▎   | 632/1000 [00:11<00:06, 55.49it/s]\r 64%|██████▍   | 638/1000 [00:11<00:06, 56.28it/s]\r 64%|██████▍   | 644/1000 [00:11<00:06, 56.63it/s]\r 65%|██████▌   | 650/1000 [00:11<00:06, 56.96it/s]\r 66%|██████▌   | 656/1000 [00:11<00:06, 57.02it/s]\r 66%|██████▌   | 662/1000 [00:11<00:05, 56.91it/s]\r 67%|██████▋   | 668/1000 [00:11<00:05, 56.27it/s]\r 67%|██████▋   | 674/1000 [00:11<00:05, 56.81it/s]\r 68%|██████▊   | 680/1000 [00:12<00:05, 56.96it/s]\r 69%|██████▊   | 686/1000 [00:12<00:05, 57.37it/s]\r 69%|██████▉   | 692/1000 [00:12<00:05, 57.69it/s]\r 70%|██████▉   | 698/1000 [00:12<00:05, 57.50it/s]\r 70%|███████   | 704/1000 [00:12<00:05, 57.35it/s]\r 71%|███████   | 710/1000 [00:12<00:05, 57.56it/s]\r 72%|███████▏  | 716/1000 [00:12<00:04, 57.96it/s]\r 72%|███████▏  | 722/1000 [00:12<00:04, 57.10it/s]\r 73%|███████▎  | 728/1000 [00:12<00:04, 57.82it/s]\r 73%|███████▎  | 734/1000 [00:12<00:04, 57.53it/s]\r 74%|███████▍  | 740/1000 [00:13<00:04, 57.56it/s]\r 75%|███████▍  | 746/1000 [00:13<00:04, 57.86it/s]\r 75%|███████▌  | 752/1000 [00:13<00:04, 58.01it/s]\r 76%|███████▌  | 758/1000 [00:13<00:04, 58.41it/s]\r 76%|███████▋  | 764/1000 [00:13<00:04, 58.52it/s]\r 77%|███████▋  | 770/1000 [00:13<00:03, 57.99it/s]\r 78%|███████▊  | 776/1000 [00:13<00:03, 58.16it/s]\r 78%|███████▊  | 782/1000 [00:13<00:03, 57.29it/s]\r 79%|███████▉  | 788/1000 [00:13<00:03, 57.99it/s]\r 79%|███████▉  | 794/1000 [00:13<00:03, 58.05it/s]\r 80%|████████  | 800/1000 [00:14<00:03, 57.67it/s]\r 81%|████████  | 806/1000 [00:14<00:03, 58.11it/s]\r 81%|████████  | 812/1000 [00:14<00:03, 58.13it/s]\r 82%|████████▏ | 818/1000 [00:14<00:03, 58.62it/s]\r 82%|████████▏ | 824/1000 [00:14<00:02, 58.83it/s]\r 83%|████████▎ | 830/1000 [00:14<00:02, 58.44it/s]\r 84%|████████▎ | 836/1000 [00:14<00:03, 54.34it/s]\r 84%|████████▍ | 842/1000 [00:14<00:02, 54.73it/s]\r 85%|████████▍ | 848/1000 [00:14<00:02, 55.56it/s]\r 85%|████████▌ | 854/1000 [00:15<00:02, 56.06it/s]\r 86%|████████▌ | 860/1000 [00:15<00:02, 56.24it/s]\r 87%|████████▋ | 866/1000 [00:15<00:02, 56.17it/s]\r 87%|████████▋ | 872/1000 [00:15<00:02, 55.99it/s]\r 88%|████████▊ | 878/1000 [00:15<00:02, 56.54it/s]\r 88%|████████▊ | 884/1000 [00:15<00:02, 56.38it/s]\r 89%|████████▉ | 890/1000 [00:15<00:01, 56.67it/s]\r 90%|████████▉ | 896/1000 [00:15<00:01, 56.34it/s]\r 90%|█████████ | 902/1000 [00:15<00:01, 57.05it/s]\r 91%|█████████ | 908/1000 [00:16<00:01, 56.52it/s]\r 91%|█████████▏| 914/1000 [00:16<00:01, 56.19it/s]\r 92%|█████████▏| 920/1000 [00:16<00:01, 55.51it/s]\r 93%|█████████▎| 926/1000 [00:16<00:01, 54.45it/s]\r 93%|█████████▎| 932/1000 [00:16<00:01, 55.44it/s]\r 94%|█████████▍| 938/1000 [00:16<00:01, 56.47it/s]\r 94%|█████████▍| 944/1000 [00:16<00:00, 56.11it/s]\r 95%|█████████▌| 950/1000 [00:16<00:00, 56.41it/s]\r 96%|█████████▌| 956/1000 [00:16<00:00, 55.77it/s]\r 96%|█████████▌| 962/1000 [00:16<00:00, 56.35it/s]\r 97%|█████████▋| 968/1000 [00:17<00:00, 56.87it/s]\r 97%|█████████▋| 974/1000 [00:17<00:00, 56.76it/s]\r 98%|█████████▊| 980/1000 [00:17<00:00, 57.05it/s]\r 99%|█████████▊| 986/1000 [00:17<00:00, 57.37it/s]\r 99%|█████████▉| 992/1000 [00:17<00:00, 58.04it/s]\r100%|█████████▉| 998/1000 [00:17<00:00, 58.14it/s]\r100%|██████████| 1000/1000 [00:17<00:00, 56.70it/s]\n"
          ]
        }
      ],
      "source": [
        "#bashでbashコマンドを有効に（このセル内のみ）\n",
        "%%bash\n",
        "python dataset_tool.py --source=./data/art-painting --dest=./data/art_painting256.zip --resolution=256x256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcS63jN9RMdy"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that the data is prepared, we can start training!  The training loop tracks FID, but the computations seems to lead to problems in colab. Hence, it is disable by default (```metrics=[]```). The loop also generates fixed noise samples after a defined amount of ticks, eg. below ```--snap=1```.\n",
        "\n",
        "日本語訳\n",
        "\n",
        "データの準備ができたので、トレーニングを開始します 学習ループはFIDを追跡しますが、その計算がcolabで問題になるようです。そのため、デフォルトでは無効になっています(metrics=[])。また、このループは、定義されたtick数の後に、固定ノイズサンプルを生成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yrjw0aes9YV_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import dnnlib\n",
        "\n",
        "from training import training_loop\n",
        "from torch_utils import training_stats\n",
        "from train import init_dataset_kwargs\n",
        "from metrics import metric_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-VAjxpv9s3T"
      },
      "outputs": [],
      "source": [
        "def launch_training(c, desc, outdir, rank=0):\n",
        "    # Pick output directory.(出力用ディレクトリの選択)\n",
        "    prev_run_dirs = []\n",
        "    if os.path.isdir(outdir):\n",
        "        prev_run_dirs = [x for x in os.listdir(outdir) if os.path.isdir(os.path.join(outdir, x))]\n",
        "\n",
        "    matching_dirs = [re.fullmatch(r'\\d{5}' + f'-{desc}', x) for x in prev_run_dirs if re.fullmatch(r'\\d{5}' + f'-{desc}', x) is not None]\n",
        "    if c.restart_every > 0 and len(matching_dirs) > 0:  # expect unique desc, continue in this directory\n",
        "        assert len(matching_dirs) == 1, f'Multiple directories found for resuming: {matching_dirs}'\n",
        "        c.run_dir = os.path.join(outdir, matching_dirs[0].group())\n",
        "    else:                     # fallback to standard\n",
        "        prev_run_ids = [re.match(r'^\\d+', x) for x in prev_run_dirs]\n",
        "        prev_run_ids = [int(x.group()) for x in prev_run_ids if x is not None]\n",
        "        cur_run_id = max(prev_run_ids, default=-1) + 1\n",
        "        c.run_dir = os.path.join(outdir, f'{cur_run_id:05d}-{desc}')\n",
        "        assert not os.path.exists(c.run_dir)\n",
        "\n",
        "\n",
        "    # Print options.\n",
        "    print()\n",
        "    print('Training options:')\n",
        "    print(json.dumps(c, indent=2))\n",
        "    print()\n",
        "    print(f'Output directory:    {c.run_dir}')\n",
        "    print(f'Number of GPUs:      {c.num_gpus}')\n",
        "    print(f'Batch size:          {c.batch_size} images')\n",
        "    print(f'Training duration:   {c.total_kimg} kimg')\n",
        "    print(f'Dataset path:        {c.training_set_kwargs.path}')\n",
        "    print(f'Dataset size:        {c.training_set_kwargs.max_size} images')\n",
        "    print(f'Dataset resolution:  {c.training_set_kwargs.resolution}')\n",
        "    print(f'Dataset labels:      {c.training_set_kwargs.use_labels}')\n",
        "    print(f'Dataset x-flips:     {c.training_set_kwargs.xflip}')\n",
        "    print()\n",
        "\n",
        "    # Create output directory.(出力用ディレクトリの作成)\n",
        "    print('Creating output directory...')\n",
        "    os.makedirs(c.run_dir, exist_ok=c.restart_every > 0)\n",
        "    with open(os.path.join(c.run_dir, 'training_options.json'), 'wt+') as f:\n",
        "        json.dump(c, f, indent=2)\n",
        "\n",
        "    # Start training\n",
        "    dnnlib.util.Logger(file_name=os.path.join(c.run_dir, 'log.txt'), file_mode='a', should_flush=False)\n",
        "    sync_device = torch.device('cuda', rank) if c.num_gpus > 1 else None\n",
        "    training_stats.init_multiprocessing(rank=rank, sync_device=sync_device)\n",
        "    training_loop.training_loop(rank=rank, **c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqqzoKQk9tRt"
      },
      "outputs": [],
      "source": [
        "def train(**kwargs):#kwargs=可変引数キーワード引数を辞書として受け取る\n",
        "    # Initialize config.(configの初期化)\n",
        "    opts = dnnlib.EasyDict(kwargs) # Command line arguments.\n",
        "    c = dnnlib.EasyDict() # Main config dict.\n",
        "    c.G_kwargs = dnnlib.EasyDict(class_name=None, z_dim=64, w_dim=128, mapping_kwargs=dnnlib.EasyDict())\n",
        "    c.G_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0,0.99], eps=1e-8)\n",
        "    c.D_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0,0.99], eps=1e-8)\n",
        "    c.data_loader_kwargs = dnnlib.EasyDict(pin_memory=True, prefetch_factor=2)\n",
        "\n",
        "    # Training set.(訓練データの生成)\n",
        "    c.training_set_kwargs, dataset_name = init_dataset_kwargs(data=opts.data)\n",
        "    if opts.cond and not c.training_set_kwargs.use_labels:\n",
        "        raise ValueError('--cond=True requires labels specified in dataset.json')\n",
        "    c.training_set_kwargs.use_labels = opts.cond\n",
        "    c.training_set_kwargs.xflip = opts.mirror\n",
        "\n",
        "    # Hyperparameters & settings.(ハイパーパラメータの設定)\n",
        "    c.num_gpus = opts.gpus\n",
        "    c.batch_size = opts.batch\n",
        "    c.batch_gpu = opts.batch_gpu or opts.batch // opts.gpus\n",
        "    c.G_kwargs.channel_base = opts.cbase\n",
        "    c.G_kwargs.channel_max = opts.cmax\n",
        "    c.G_kwargs.mapping_kwargs.num_layers = 2\n",
        "    c.G_opt_kwargs.lr = (0.002 if opts.cfg == 'stylegan2' else 0.0025) if opts.glr is None else opts.glr\n",
        "    c.D_opt_kwargs.lr = opts.dlr\n",
        "    c.metrics = opts.metrics\n",
        "    c.total_kimg = opts.kimg\n",
        "    c.kimg_per_tick = opts.tick\n",
        "    c.image_snapshot_ticks = c.network_snapshot_ticks = opts.snap\n",
        "    c.random_seed = c.training_set_kwargs.random_seed = opts.seed\n",
        "    c.data_loader_kwargs.num_workers = opts.workers\n",
        "\n",
        "    # Sanity checks.(バグ確認)\n",
        "    if c.batch_size % c.num_gpus != 0:\n",
        "        raise ValueError('--batch must be a multiple of --gpus')\n",
        "    if c.batch_size % (c.num_gpus * c.batch_gpu) != 0:\n",
        "        raise ValueError('--batch must be a multiple of --gpus times --batch-gpu')\n",
        "    if any(not metric_main.is_valid_metric(metric) for metric in c.metrics):\n",
        "        raise ValueError('\\n'.join(['--metrics can only contain the following values:'] + metric_main.list_valid_metrics()))\n",
        "\n",
        "    # Base configuration.(基本構成定義？)(cfgでganの種類を定義(stylegan2 or fastgan))\n",
        "    c.ema_kimg = c.batch_size * 10 / 32\n",
        "    if opts.cfg == 'stylegan2':\n",
        "        c.G_kwargs.class_name = 'pg_modules.networks_stylegan2.Generator'\n",
        "        c.G_kwargs.fused_modconv_default = 'inference_only' # Speed up training by using regular convolutions instead of grouped convolutions.\n",
        "        use_separable_discs = True\n",
        "\n",
        "    elif opts.cfg == 'fastgan':\n",
        "        c.G_kwargs = dnnlib.EasyDict(class_name='pg_modules.networks_fastgan.Generator', cond=opts.cond)\n",
        "        c.G_opt_kwargs.lr = c.D_opt_kwargs.lr = 0.0002\n",
        "        use_separable_discs = False\n",
        "\n",
        "    # Restart.(やり直し)\n",
        "    c.restart_every = opts.restart_every\n",
        "\n",
        "    # Description string.(説明)\n",
        "    desc = f'{opts.cfg:s}-{dataset_name:s}-gpus{c.num_gpus:d}-batch{c.batch_size:d}'\n",
        "    if opts.desc is not None:\n",
        "        desc += f'-{opts.desc}'\n",
        "\n",
        "    # Projected and Multi-Scale Discriminators\n",
        "    c.loss_kwargs = dnnlib.EasyDict(class_name='training.loss.ProjectedGANLoss')\n",
        "    c.D_kwargs = dnnlib.EasyDict(\n",
        "        class_name='pg_modules.discriminator.ProjectedDiscriminator',\n",
        "        diffaug=True,\n",
        "        interp224=(c.training_set_kwargs.resolution < 224),\n",
        "        backbone_kwargs=dnnlib.EasyDict(),\n",
        "    )\n",
        "\n",
        "    c.D_kwargs.backbone_kwargs.cout = 64\n",
        "    c.D_kwargs.backbone_kwargs.expand = True\n",
        "    c.D_kwargs.backbone_kwargs.proj_type = 2\n",
        "    c.D_kwargs.backbone_kwargs.num_discs = 4\n",
        "    c.D_kwargs.backbone_kwargs.separable = use_separable_discs\n",
        "    c.D_kwargs.backbone_kwargs.cond = opts.cond\n",
        "\n",
        "    # Launch.\n",
        "    launch_training(c=c, desc=desc, outdir=opts.outdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKHfWFKe9tWB",
        "outputId": "a9f759e4-05ed-46c4-c2c4-d4e0282d0797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"pg_modules.networks_fastgan.Generator\",\n",
            "    \"cond\": false\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0002\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0002\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 0\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./data/zipfgosavasq.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 340,\n",
            "    \"xflip\": 1,\n",
            "    \"resolution\": 566,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 64,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 10000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 1,\n",
            "  \"network_snapshot_ticks\": 1,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 20.0,\n",
            "  \"restart_every\": 999999,\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.ProjectedGANLoss\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"pg_modules.discriminator.ProjectedDiscriminator\",\n",
            "    \"diffaug\": true,\n",
            "    \"interp224\": false,\n",
            "    \"backbone_kwargs\": {\n",
            "      \"cout\": 64,\n",
            "      \"expand\": true,\n",
            "      \"proj_type\": 2,\n",
            "      \"num_discs\": 4,\n",
            "      \"separable\": false,\n",
            "      \"cond\": false\n",
            "    }\n",
            "  },\n",
            "  \"run_dir\": \"training-runs/00000-fastgan-zipfgosavasq-gpus1-batch64-\"\n",
            "}\n",
            "\n",
            "Output directory:    training-runs/00000-fastgan-zipfgosavasq-gpus1-batch64-\n",
            "Number of GPUs:      1\n",
            "Batch size:          64 images\n",
            "Training duration:   10000 kimg\n",
            "Dataset path:        ./data/zipfgosavasq.zip\n",
            "Dataset size:        340 images\n",
            "Dataset resolution:  566\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  680\n",
            "Image shape: [3, 566, 566]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b3a60c3b1b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mrestart_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m999999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-34-1817d67a9e4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Launch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mlaunch_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-5e752ff2afa4>\u001b[0m in \u001b[0;36mlaunch_training\u001b[0;34m(c, desc, outdir, rank)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0msync_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gpus\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtraining_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_multiprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtraining_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/projected_gan/training/training_loop.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(run_dir, training_set_kwargs, data_loader_kwargs, G_kwargs, D_kwargs, G_opt_kwargs, D_opt_kwargs, loss_kwargs, metrics, random_seed, num_gpus, rank, batch_size, batch_gpu, ema_kimg, ema_rampup, G_reg_interval, D_reg_interval, total_kimg, kimg_per_tick, image_snapshot_ticks, network_snapshot_ticks, resume_pkl, resume_kimg, cudnn_benchmark, abort_fn, progress_fn, restart_every)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Constructing networks...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mcommon_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_class_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mG_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcommon_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# subclass of torch.nn.Module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_class_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mD_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcommon_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# subclass of torch.nn.Module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mG_ema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/dnnlib/util.py\u001b[0m in \u001b[0;36mconstruct_class_by_name\u001b[0;34m(class_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_class_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;34m\"\"\"Finds the python class with the given name and constructs it with the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_func_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/dnnlib/util.py\u001b[0m in \u001b[0;36mcall_func_by_name\u001b[0;34m(func_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mfunc_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_obj_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/pg_modules/networks_fastgan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, z_dim, c_dim, w_dim, img_resolution, img_channels, ngf, cond, mapping_kwargs, synthesis_kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyMapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# to fit the StyleGAN API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mSynthesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastganSynthesisCond\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mFastganSynthesis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynthesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSynthesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_resolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msynthesis_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/projected_gan/pg_modules/networks_fastgan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ngf, z_dim, nc, img_resolution, lite)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mse_256\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_big\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_resolution\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg_resolution\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 566"
          ]
        }
      ],
      "source": [
        "# start training!\n",
        "%cp /content/zipfgosavasq.zip /content/projected_gan/data\n",
        "train(\n",
        "    outdir='training-runs', #出力用ディレクトリ\n",
        "    cfg='fastgan',#ganの選択\n",
        "    #data='./data/art_painting256.zip', #訓練データ置き場\n",
        "    data='./data/zipfgosavasq.zip', #訓練データ置き場,\n",
        "    gpus=1, #gpusの数設定\n",
        "    batch=64, #batchのsize\n",
        "    cond=False, #\n",
        "    mirror=1, \n",
        "    batch_gpu=8, \n",
        "    cbase=32768, \n",
        "    cmax=512, \n",
        "    glr=None, \n",
        "    dlr=0.002, \n",
        "    desc='', \n",
        "    metrics=[],\n",
        "    kimg=10000, \n",
        "    tick=4, \n",
        "    snap=1, \n",
        "    seed=0, \n",
        "    workers=0,\n",
        "    restart_every=999999,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqYeDzg3KUMG"
      },
      "source": [
        "To inspect the samples, click on the folder symbol on the left and navigate to \n",
        "\n",
        "```projected_gan/training-runs/YOUR_RUN```\n",
        "\n",
        "The files ```fakesXXXXXX.png``` are the samples for a fixed noise vector at point."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ENlESm6i8RnD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "projected_gan.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}